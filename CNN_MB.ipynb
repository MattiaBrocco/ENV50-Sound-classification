{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744bfa6e",
   "metadata": {},
   "source": [
    "# CNN for audio classification\n",
    "\n",
    "##### SOURCES\n",
    "[1] [CNN for audio (MEDIUM)](https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab)  \n",
    "[2] [Types of DCT](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.dct.html#scipy.fftpack.dct)\n",
    "\n",
    "Default sampling rate of `librosa` is 22050, while for `scipy` is 44100. This implies that we have half of the length of the sequence with the former library (110250 against 220500).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592da296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T15:26:41.488268Z",
     "start_time": "2023-01-02T15:26:24.186181Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy.io import wavfile\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluation\n",
    "import CNN_support as cnns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a115cec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T15:26:41.828237Z",
     "start_time": "2023-01-02T15:26:41.491121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('.\\\\data\\\\meta\\\\esc50.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c6cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T07:46:48.674321Z",
     "start_time": "2023-01-02T07:42:17.451571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pppp = cnns.SoundPreprocessing(n_fft = 1000, n_mfcc = 10, sr = 441000, max_size = (200, 1000))\n",
    "\n",
    "#W, Z = pppp.get_features(df = data, filepath = \".\\\\data\\\\audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d3fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T10:44:50.311038Z",
     "start_time": "2023-01-02T10:44:50.054512Z"
    }
   },
   "outputs": [],
   "source": [
    "s, a = wavfile.read(\".\\\\data\\\\audio\\\\{}\".format(data.loc[10, \"filename\"]))\n",
    "a = a.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b6263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T10:42:52.301816Z",
     "start_time": "2023-01-02T10:42:51.935812Z"
    }
   },
   "outputs": [],
   "source": [
    "mfcc_try = librosa.feature.mfcc(y = a, sr = s, hop_length = 512, n_mfcc = 60)\n",
    "mfcc_try = np.divide(mfcc_try, np.linalg.norm(mfcc_try))\n",
    "chromogram_try = librosa.feature.chroma_stft(y = a, sr = s, hop_length = 512,\n",
    "                                             win_length = 1024, n_chroma = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49ca36",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233ad077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T11:29:27.578760Z",
     "start_time": "2023-01-02T11:26:34.063345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Get data for CNN\n",
    "X = []\n",
    "y = np.zeros(shape = (len(data), 1))\n",
    "\n",
    "for i in data.index:\n",
    "    \n",
    "    sr, aud = wavfile.read(\".\\\\data\\\\audio\\\\{}\".format(data.loc[i, \"filename\"]))\n",
    "    aud = aud.astype(np.float32)\n",
    "    \n",
    "    MFCC = librosa.feature.mfcc(y = aud, sr = sr, hop_length = 512, n_mfcc = 60)\n",
    "    chromagram = librosa.feature.chroma_stft(y = aud.astype(np.float32), sr = sr,\n",
    "                                             hop_length = 512, win_length = 1024,\n",
    "                                             n_chroma = 60)\n",
    "    delta = librosa.feature.delta(MFCC)\n",
    "    \n",
    "    instance = np.dstack((MFCC, chromagram, delta))\n",
    "    \n",
    "    X += [instance]\n",
    "    \n",
    "    y[i] = data.loc[i, \"target\"]\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ec06f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T11:46:12.105657Z",
     "start_time": "2023-01-02T11:29:27.581732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "# SOURCE: https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6\n",
    "\n",
    "np.random.seed(42)\n",
    "indexed_samples = np.random.choice(X.shape[0], size = 4000,\n",
    "                                   replace = True)\n",
    "np.random.seed(101)\n",
    "randn_seeds = np.random.choice(5000, size = 4000,\n",
    "                               replace = False)\n",
    "\n",
    "new_X = []\n",
    "new_y = np.zeros(shape = (len(indexed_samples), 1))\n",
    "for n, i in enumerate(indexed_samples):\n",
    "    \n",
    "    sr_sample, sample = wavfile.read(\".\\\\data\\\\audio\\\\{}\".format(data.loc[i, \"filename\"]))\n",
    "    sample = sample.astype(np.float32)\n",
    "    \n",
    "    if n%5 == 0:\n",
    "        # NOISE INJECTION\n",
    "        np.random.seed(randn_seeds[n])\n",
    "        noise = np.random.randn(len( sample ))\n",
    "        augmented_data = (sample + noise).astype(np.float32)\n",
    "        \n",
    "    elif n%5 == 1:\n",
    "        # TIME SHIFT: right shift\n",
    "        np.random.seed(randn_seeds[n])\n",
    "        shift = -1*np.random.randint(sr_sample * 0.2) # 0.2 length of sequence max\n",
    "        augmented_data = np.roll(sample, shift)\n",
    "        # Set to silence for heading/ tailing\n",
    "        augmented_data[shift:] = 0\n",
    "        \n",
    "    elif n%5 == 2:\n",
    "        # PITCH SHIFT: shift down by 3\n",
    "        augmented_data = librosa.effects.pitch_shift(y = sample, sr = sr_sample,\n",
    "                                                     n_steps = 3)\n",
    "    elif n%5 == 3:\n",
    "        # SPEED SHIFT: faster\n",
    "        augmented_data = librosa.effects.time_stretch(y = sample, rate = 1.2)\n",
    "        augmented_data = np.append(augmented_data,\n",
    "                                   np.zeros(shape = len(sample) - len(augmented_data)))\n",
    "    else:\n",
    "        # SPEED SHIFT: slower (returns longer array)\n",
    "        augmented_data = librosa.effects.time_stretch(y = sample, rate = 0.8)\n",
    "        augmented_data = augmented_data[:len(sample)]\n",
    "    \n",
    "    \n",
    "    new_MFCC = librosa.feature.mfcc(y = augmented_data, sr = sr_sample,\n",
    "                                    hop_length = 512, n_mfcc = 60)\n",
    "    new_chromagram = librosa.feature.chroma_stft(y = augmented_data, sr = sr_sample,\n",
    "                                                 hop_length = 512, win_length = 1024,\n",
    "                                                 n_chroma = 60)\n",
    "    new_delta = librosa.feature.delta(new_MFCC)\n",
    "    \n",
    "    new_instance = np.dstack((new_MFCC, new_chromagram, new_delta))\n",
    "    \n",
    "    new_X += [new_instance]\n",
    "    new_y[n] = y[i]\n",
    "    \n",
    "new_X = np.array(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af319c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T11:46:39.671549Z",
     "start_time": "2023-01-02T11:46:12.121578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get stuff together\n",
    "X = np.vstack((X, new_X))\n",
    "y = np.vstack((y, new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01736996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T12:37:42.197050Z",
     "start_time": "2023-01-02T12:37:41.207696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 60, 431, 3), (6000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd7af0f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T13:49:03.570049Z",
     "start_time": "2023-01-02T13:47:26.093972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 3600\n",
      "Validation examples: 900\n",
      "Test examples: 1500\n",
      "\n",
      "Input shape: (60, 431, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = .75, random_state = 42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size = .8, random_state = 42)\n",
    "\n",
    "print(\"Training examples: {}\".format(y_train.shape[0]))\n",
    "print(\"Validation examples: {}\".format(y_valid.shape[0]))\n",
    "print(\"Test examples: {}\".format(y_test.shape[0]))\n",
    "print()\n",
    "print(\"Input shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f96a3812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T14:06:47.542469Z",
     "start_time": "2023-01-02T14:06:29.319142Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------- #\n",
    "# LOAD DATA FROM FILES #\n",
    "# -------------------- #\n",
    "\n",
    "X_train = np.vstack((torch.load(\".//data/CNN_X_train_1.pt\"),\n",
    "                     torch.load(\".//data/CNN_X_train_2.pt\"),\n",
    "                     torch.load(\".//data/CNN_X_train_3.pt\")))\n",
    "X_valid = torch.load(\".//data/CNN_X_valid.pt\")\n",
    "X_test = torch.load(\".//data/CNN_X_test.pt\")\n",
    "y_train = torch.load(\".//data/CNN_y_train.pt\")\n",
    "y_valid = torch.load(\".//data/CNN_y_valid.pt\")\n",
    "y_test = torch.load(\".//data/CNN_y_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d78582dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T14:22:57.619120Z",
     "start_time": "2023-01-02T14:22:57.336609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f9358",
   "metadata": {},
   "source": [
    "## Algo tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "015f0a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-02T14:23:27.558103Z",
     "start_time": "2023-01-02T14:23:27.171294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"M1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 60, 431, 40)       430960    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 49, 141, 40)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 49, 141, 40)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 49, 141, 40)       4840      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 25, 28, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 28000)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                1400050   \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,838,400\n",
      "Trainable params: 1,838,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.Sequential([keras.layers.Conv2D(filters = 40, kernel_size = [57, 63],\n",
    "                                                      padding = \"same\", activation = \"relu\",\n",
    "                                                      input_shape = [60, 431, 3]),\n",
    "                                  keras.layers.MaxPool2D(pool_size = (12, 10), strides = (1, 3)),\n",
    "                                  keras.layers.Dropout(rate = .5),\n",
    "                                  keras.layers.Conv2D(filters = 40, kernel_size = (1, 3),\n",
    "                                                      padding = \"same\", activation = \"relu\"),\n",
    "                                  keras.layers.MaxPool2D(pool_size = (1, 3), strides = (2, 5)),\n",
    "                                  keras.layers.Flatten(),\n",
    "                                  #keras.layers.Dense(5000, activation = \"relu\"),\n",
    "                                  #keras.layers.Dropout(rate = .5),\n",
    "                                  keras.layers.Dense(50, activation = \"relu\"),\n",
    "                                  keras.layers.Dropout(rate = .5),\n",
    "                                  keras.layers.Dense(50, activation = \"softmax\") ], name = \"M1\")\n",
    "\n",
    "model1.compile(loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"],\n",
    "               optimizer = keras.optimizers.Adam(learning_rate = 1e-4))\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d8187",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-02T14:23:35.273Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size1 = int(X_train.shape[0]/10)\n",
    "history1 = model1.fit(X_train, y_train, epochs = 100, batch_size = batch_size1,\n",
    "                      validation_data = (X_valid, y_valid), verbose = 0,\n",
    "                      callbacks = [keras.callbacks.EarlyStopping(patience = 5)])\n",
    "\n",
    "evaluation.plot_loss(history1)\n",
    "evaluation.plot_accuracy(history1)\n",
    "\n",
    "scores1 = model1.evaluate(X_test, y_test, verbose = 2)\n",
    "print(\"=\"*71)\n",
    "print(\"Accuracy on test: {:.2f}%\".format(scores1[1]*100))\n",
    "print(\"Memory used: {:.1f} Mb\".format(\n",
    "    evaluation.keras_model_memory_usage_in_bytes(model = model1,\n",
    "                                                 batch_size = batch_size1)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffdd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf59b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f9dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22638336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216a4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898d237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82920135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da572295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184f3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3edc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f3634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ce60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
